{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in the data\n",
    "# adapted code from [1]\n",
    "\n",
    "users_columns = ['user_id', 'gender', 'age', 'occupation', 'zip_code']\n",
    "users = pd.read_table('users.dat', sep='::', header=None, names=users_columns, engine='python')\n",
    "\n",
    "ratings_columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_table('ratings.dat', sep='::', header=None, names=ratings_columns, engine='python')\n",
    "\n",
    "movies_columns = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_table('movies.dat', sep='::', header=None, names=movies_columns, engine='python')\n",
    "\n",
    "# merging dataframes\n",
    "merged = pd.merge(pd.merge(ratings, users), movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing columns that we will use\n",
    "trim = merged[['user_id', 'title','rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Approach 1\n",
    "\n",
    "\"global average rating\" algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code partially adapted from [2]\n",
    "\n",
    "def na_global_average(df, k=5):\n",
    "\n",
    "    # k-fold CV set-up\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    \n",
    "    # initializing lists\n",
    "    train_RMSE_per_round = []\n",
    "    train_MAE_per_round = []\n",
    "    test_RMSE_per_round = []\n",
    "    test_MAE_per_round = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "\n",
    "        train = df['rating'][train_index]\n",
    "\n",
    "        # global average rating in training data\n",
    "        global_mean = np.mean(train)\n",
    "        \n",
    "        y_test = df['rating'][test_index]\n",
    "        y_pred = [global_mean]*len(test_index)\n",
    "        \n",
    "        # train accuracy\n",
    "        RMSE_train = math.sqrt(np.mean((train-global_mean)**2))\n",
    "        MAE_train = np.mean(abs(train-global_mean))\n",
    "        \n",
    "        train_RMSE_per_round.append(RMSE_train)\n",
    "        train_MAE_per_round.append(MAE_train)\n",
    "        \n",
    "        # test accuracy\n",
    "        RMSE_test = math.sqrt(np.mean((y_pred-y_test)**2))\n",
    "        MAE_test = np.mean(abs(y_pred-y_test))\n",
    "\n",
    "        test_RMSE_per_round.append(RMSE_test)\n",
    "        test_MAE_per_round.append(MAE_test)\n",
    "    \n",
    "    return(train_RMSE_per_round, train_MAE_per_round,\n",
    "           test_RMSE_per_round, test_MAE_per_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(seed=123)\n",
    "\n",
    "# naive approach 1; 5-fold CV\n",
    "experiment_1 = na_global_average(df=trim, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results for the \"global average rating\" algorithm\n",
    "\n",
    "# train accuracy; RMSE; round 1-5\n",
    "print(np.round(experiment_1[0], 4))\n",
    "# train accuracy; RMSE; estimate\n",
    "print(np.round(np.mean(experiment_1[0]), 4))\n",
    "\n",
    "# train accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_1[1], 4))\n",
    "# train accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_1[1]), 4))\n",
    "\n",
    "# test accuracy; RSME; round 1-5\n",
    "print(np.round(experiment_1[2], 4))\n",
    "# test accuracy; RSME; estimate\n",
    "print(np.round(np.mean(experiment_1[2]), 4))\n",
    "\n",
    "# test accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_1[3], 4))\n",
    "# test accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_1[3]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Approach 2\n",
    "\n",
    "\"movie average rating\" algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code partially adapted from [2]\n",
    "\n",
    "def na_movie_average(df, k):\n",
    "\n",
    "    # setting up k-fold cross validation\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "    # initializing lists\n",
    "    train_RMSE_per_round = []\n",
    "    train_MAE_per_round = []\n",
    "    test_RMSE_per_round = []\n",
    "    test_MAE_per_round = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df): # O(N)\n",
    "        \n",
    "        train = df.loc[train_index.tolist()]\n",
    "    \n",
    "        # average rating per title in training data\n",
    "        title_means = train.pivot_table(values='rating', index='title', aggfunc='mean') # O(M)\n",
    "        # change index 'title' into column 'title'\n",
    "        title_means = title_means.reset_index()\n",
    "        # change column name 'rating' into 'title_mean'\n",
    "        title_means.rename(columns={'rating': 'title_mean'}, inplace=True)\n",
    "    \n",
    "        # add missing titles if missing\n",
    "        if set(train.title.unique()) != set(df.title.unique()):\n",
    "            # index of titles missing in training set\n",
    "            mis_ind = np.invert(np.isin(element = df.title.unique(), test_elements = train.title.unique()))\n",
    "            # missing title in training set\n",
    "            mis_tit = df.title.unique()[mis_ind]\n",
    "            # dataframe of missing titles in training set\n",
    "            mis_tit = pd.DataFrame(data = mis_tit, columns = ['title'])\n",
    "            # adding column with global mean rating as mean rating for missing title\n",
    "            mis_tit.insert(loc = 1, column = 'title_mean', value = train.rating.mean())\n",
    "            # adding missing titles to title_means in training data \n",
    "            title_means = pd.concat(objs = [title_means, mis_tit], axis = 0, ignore_index=True)\n",
    "    \n",
    "        # train accuracy\n",
    "        xy_train = pd.merge(train, title_means)\n",
    "        # train RMSE\n",
    "        RMSE_train = math.sqrt(np.mean((xy_train['rating']-xy_train['title_mean'])**2))\n",
    "        # train MAE\n",
    "        MAE_train = np.mean(abs(xy_train['rating']-xy_train['title_mean']))\n",
    "        \n",
    "        train_RMSE_per_round.append(RMSE_train)\n",
    "        train_MAE_per_round.append(MAE_train)\n",
    "        \n",
    "        # test accuracy\n",
    "        x_test = df.loc[test_index.tolist()]\n",
    "        # x and y test data\n",
    "        xy_test = pd.merge(x_test, title_means) \n",
    "        # test RMSE\n",
    "        RMSE_test = math.sqrt(np.mean((xy_test['rating'] - xy_test['title_mean'])**2))\n",
    "        # test MAE\n",
    "        MAE_test = np.mean(abs(xy_test['rating'] - xy_test['title_mean']))\n",
    "        \n",
    "        test_RMSE_per_round.append(RMSE_test)\n",
    "        test_MAE_per_round.append(MAE_test)\n",
    "    \n",
    "    return(train_RMSE_per_round, train_MAE_per_round,\n",
    "           test_RMSE_per_round, test_MAE_per_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(seed=123)\n",
    "\n",
    "# naive approach 2; 5-fold CV\n",
    "experiment_2 = na_movie_average(df=trim, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results for the \"movie average rating\" algorithm\n",
    "\n",
    "# train accuracy; RMSE; round 1-5\n",
    "print(np.round(experiment_2[0], 4))\n",
    "# train accuracy; RMSE; estimate\n",
    "print(np.round(np.mean(experiment_2[0]), 4))\n",
    "\n",
    "# train accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_2[1], 4))\n",
    "# train accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_2[1]), 4))\n",
    "\n",
    "# test accuracy; RMSE; round 1-5\n",
    "print(np.round(experiment_2[2], 4))\n",
    "# test accuracy; RMSE; estimate\n",
    "print(np.round(np.mean(experiment_2[2]), 4))\n",
    "\n",
    "# test accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_2[3], 4))\n",
    "# test accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_2[3]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Approach 3\n",
    "\n",
    "\"user average rating\" algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted code partially from [2]\n",
    "\n",
    "def na_user_average(df, k):\n",
    "\n",
    "    # setting up k-fold cross validation\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    \n",
    "    # initializing lists\n",
    "    train_RMSE_per_round = []\n",
    "    train_MAE_per_round = []\n",
    "    test_RMSE_per_round = []\n",
    "    test_MAE_per_round = []\n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "\n",
    "        train = df.loc[train_index.tolist()]\n",
    "\n",
    "        # mean per user in training data\n",
    "        user_means = train.pivot_table(values='rating', index='user_id', aggfunc='mean')\n",
    "        # change index 'user_id' into column 'user_id' \n",
    "        user_means = user_means.reset_index()\n",
    "        # change column name 'rating' into 'user_mean'\n",
    "        user_means.rename(columns={'rating': 'user_mean'}, inplace=True) \n",
    "\n",
    "        # add missing users if missing\n",
    "        if set(train.user_id.unique()) != set(df.user_id.unique()):\n",
    "            # index of users missing in training set\n",
    "            mis_ind = np.invert(np.isin(element = df.user_id.unique(), test_elements = train.user_id.unique()))\n",
    "            # missing users in training set\n",
    "            mis_use = df.user_id.unique()[mis_ind]\n",
    "            # dataframe of missing users in training set\n",
    "            mis_use = pd.DataFrame(data = mis_tit, columns = ['user_id'])\n",
    "            # adding column with global mean rating as mean rating for user\n",
    "            mis_use.insert(loc = 1, column = 'user_mean', value = train.rating.mean())\n",
    "            # adding missing users to user_means in training data \n",
    "            user_means = pd.concat(objs = [user_means, mis_tit], axis = 0, ignore_index=True)\n",
    "        \n",
    "        # train accuracy\n",
    "        xy_train = pd.merge(train, user_means)\n",
    "        # train RMSE\n",
    "        RMSE_train = math.sqrt(np.mean((xy_train['rating']-xy_train['user_mean'])**2))\n",
    "        # train MAE\n",
    "        MAE_train = np.mean(abs(xy_train['rating']-xy_train['user_mean']))\n",
    "        \n",
    "        train_RMSE_per_round.append(RMSE_train)\n",
    "        train_MAE_per_round.append(MAE_train)\n",
    "        \n",
    "        # test accuracy\n",
    "        x_test = df.loc[test_index.tolist()]\n",
    "        # x and y test data\n",
    "        xy_test = pd.merge(x_test, user_means) \n",
    "        # test RMSE\n",
    "        RMSE_test = math.sqrt(np.mean((xy_test['rating']-xy_test['user_mean'])**2))\n",
    "        # test MAE\n",
    "        MAE_test = np.mean(abs(xy_test['rating']-xy_test['user_mean']))\n",
    "        \n",
    "        test_RMSE_per_round.append(RMSE_test)\n",
    "        test_MAE_per_round.append(MAE_test)\n",
    "        \n",
    "    return(train_RMSE_per_round, train_MAE_per_round,\n",
    "           test_RMSE_per_round, test_MAE_per_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(seed=123)\n",
    "\n",
    "# naive approach 3; 5-fold CV\n",
    "experiment_3 = na_user_average(df=trim, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results for the \"user average rating\" algorithm\n",
    "\n",
    "# train accuracy; RMSE; round 1-5\n",
    "print(np.round(experiment_3[0], 4))\n",
    "# train accuracy; RMSE; estimate\n",
    "print(np.round(np.mean(experiment_3[0]), 4))\n",
    "\n",
    "# train accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_3[1], 4))\n",
    "# train accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_3[1]), 4))\n",
    "\n",
    "# test accuracy; RSME; round 1-5\n",
    "print(np.round(experiment_3[2], 4))\n",
    "# test accuracy; RSME; estimate\n",
    "print(np.round(np.mean(experiment_3[2]), 4))\n",
    "\n",
    "# test accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_3[3], 4))\n",
    "# test accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_3[3]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Approach 4 & 5\n",
    "\n",
    "Naive approach 4: \"simple linear combination\" algorithm\n",
    "\n",
    "Naive approach 5: \"full linear combination\" algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code partially adapted from [2] and [3]\n",
    "\n",
    "def na_linear_combination(df, k, intcept=True):\n",
    "    \n",
    "    # setting up k-fold cross validation\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    # linear model without intercept\n",
    "    model = linear_model.LinearRegression(fit_intercept=intcept)\n",
    "    \n",
    "    # initializing lists\n",
    "    train_RMSE_per_round = []\n",
    "    train_MAE_per_round = []\n",
    "    test_RMSE_per_round = []\n",
    "    test_MAE_per_round = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(df):\n",
    "\n",
    "        train = df.loc[train_index.tolist()]\n",
    "\n",
    "        # mean rating per user in the training data\n",
    "        user_means = train.pivot_table(values='rating', index='user_id', aggfunc='mean')\n",
    "        user_means = user_means.reset_index()\n",
    "        user_means.rename(columns={'rating': 'user_mean'}, inplace=True)\n",
    "\n",
    "        # mean rating per title in the training data\n",
    "        title_means = train.pivot_table(values='rating', index='title', aggfunc='mean')\n",
    "        title_means = title_means.reset_index()\n",
    "        title_means.rename(columns={'rating': 'title_mean'}, inplace=True)\n",
    "\n",
    "        # add missing users if missing\n",
    "        if set(train.user_id.unique()) != set(df.user_id.unique()):\n",
    "            # index of users missing in training set\n",
    "            mis_ind = np.invert(np.isin(element = df.user_id.unique(), test_elements = train.user_id.unique()))\n",
    "            # missing users in training set\n",
    "            mis_use = df.user_id.unique()[mis_ind]\n",
    "            # dataframe of missing users in training set\n",
    "            mis_use = pd.DataFrame(data = mis_tit, columns = ['user_id'])\n",
    "            # adding column with global mean rating as mean rating for user\n",
    "            mis_use.insert(loc = 1, column = 'user_mean', value = train.rating.mean())\n",
    "            # adding missing users to user_means in training data \n",
    "            user_means = pd.concat(objs = [user_means, mis_tit], axis = 0, ignore_index=True)\n",
    "\n",
    "        # add missing titles if missing\n",
    "        if set(train.title.unique()) != set(df.title.unique()):\n",
    "            # index of titles missing in training set\n",
    "            mis_ind = np.invert(np.isin(element = df.title.unique(), test_elements = train.title.unique()))\n",
    "            # missing title in training set\n",
    "            mis_tit = df.title.unique()[mis_ind]\n",
    "            # dataframe of missing titles in training set\n",
    "            mis_tit = pd.DataFrame(data = mis_tit, columns = ['title'])\n",
    "            # adding column with global mean rating as mean rating for missing title\n",
    "            mis_tit.insert(loc = 1, column = 'title_mean', value = train.rating.mean())\n",
    "            # adding missing titles to title_means in training data \n",
    "            title_means = pd.concat(objs = [title_means, mis_tit], axis = 0, ignore_index=True)\n",
    "\n",
    "        # add column with mean value per user\n",
    "        train = pd.merge(train, user_means)\n",
    "        # add column with mean value per title \n",
    "        train = pd.merge(train, title_means) \n",
    "\n",
    "        # x training data\n",
    "        x_train = train[['user_mean', 'title_mean']]\n",
    "        # y training data\n",
    "        y_train = train[['rating']] \n",
    "\n",
    "        test = df.loc[test_index.tolist()]\n",
    "        # add column with mean value per user\n",
    "        test = pd.merge(test, user_means)\n",
    "        # add column with mean value per title \n",
    "        test = pd.merge(test, title_means) \n",
    "\n",
    "        # x testing data\n",
    "        x_test = test[['user_mean', 'title_mean']]\n",
    "        # y testing data\n",
    "        y_test = test[['rating']] \n",
    "\n",
    "        # build training model\n",
    "        model.fit(x_train, y_train) # with intercept\n",
    "        # apply trained model to make prediction (on test set)\n",
    "        \n",
    "        # train accuracy\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        # rounding invalid ratings\n",
    "        y_pred_train[y_pred_train < 1] = 1\n",
    "        y_pred_train[y_pred_train > 5] = 5\n",
    "        \n",
    "        # train RMSE\n",
    "        RMSE_train = math.sqrt( np.mean( (y_pred_train - y_train)**2 ) )\n",
    "        # train MAE\n",
    "        MAE_train = np.mean( abs(y_pred_train - y_train) )[0]\n",
    "        \n",
    "        train_RMSE_per_round.append(RMSE_train)\n",
    "        train_MAE_per_round.append(MAE_train)\n",
    "\n",
    "        # test accuracy\n",
    "        y_pred_test = model.predict(x_test)\n",
    "        # rounding invalid ratings\n",
    "        y_pred_test[y_pred_test < 1] = 1\n",
    "        y_pred_test[y_pred_test > 5] = 5\n",
    "        \n",
    "        # test RMSE\n",
    "        RMSE_test = math.sqrt( np.mean( (y_pred_test - y_test)**2 ) )\n",
    "        # test MAE\n",
    "        MAE_test = np.mean( abs(y_pred_test - y_test) )[0]\n",
    "\n",
    "        test_RMSE_per_round.append(RMSE_test)\n",
    "        test_MAE_per_round.append(MAE_test)\n",
    "        \n",
    "    return(train_RMSE_per_round, train_MAE_per_round,\n",
    "           test_RMSE_per_round, test_MAE_per_round)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results for linear combination without intercept (simple linear combination)\n",
    "\n",
    "# set seed\n",
    "np.random.seed(seed=123)\n",
    "\n",
    "# naive approach 4; 5-fold CV\n",
    "experiment_4 = na_linear_combination(df=trim, k=5, intcept=False)\n",
    "\n",
    "# train accuracy; RMSE; round 1-5\n",
    "print(np.round(experiment_4[0], 4))\n",
    "# train accuracy; RMSE; estimate\n",
    "print(np.round(np.mean(experiment_2[0]), 4))\n",
    "\n",
    "# train accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_4[1], 4))\n",
    "# train accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_2[1]), 4))\n",
    "\n",
    "# test accuracy; RMSE; round 1-5\n",
    "print(np.round(experiment_4[2], 4))\n",
    "# test accuracy; RMSE; estimate\n",
    "print(np.round(np.mean(experiment_2[2]), 4))\n",
    "\n",
    "# test accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_4[3], 4))\n",
    "# test accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_2[3]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results for linear combination with intercept (full linear combination)\n",
    "\n",
    "# set seed\n",
    "np.random.seed(seed=123)\n",
    "\n",
    "# naive approach 5; 5-fold CV\n",
    "experiment_5 = na_linear_combination(df=trim, k=5, intcept=True)\n",
    "\n",
    "# train accuracy; RMSE; round 1-5\n",
    "print(np.round(experiment_2[0], 4))\n",
    "# train accuracy; RMSE; estimate\n",
    "print(np.round(np.mean(experiment_5[0]), 4))\n",
    "\n",
    "# train accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_2[1], 4))\n",
    "# train accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_5[1]), 4))\n",
    "\n",
    "# test accuracy; RMSE; round 1-5\n",
    "print(np.round(experiment_2[2], 4))\n",
    "# test accuracy; RMSE; estimate\n",
    "print(np.round(np.mean(experiment_5[2]), 4))\n",
    "\n",
    "# test accuracy; MAE; round 1-5\n",
    "print(np.round(experiment_2[3], 4))\n",
    "# test accuracy; MAE; estimate\n",
    "print(np.round(np.mean(experiment_5[3]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Naive Approaches\n",
    "\n",
    "Comparing the achieved accuracy on the test data\n",
    "\n",
    "1. global average\n",
    "2. movie average\n",
    "3. user average\n",
    "5. linear combination without intercept\n",
    "4. linear combination with intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE and MAE on test data using 5-fold CV')\n",
    "print()\n",
    "\n",
    "print('Algorithm: \"global average rating\"')\n",
    "print('RMSE:', np.round(np.mean(experiment_1[2]), 4))\n",
    "print('MAE:', np.round(np.mean(experiment_1[3]), 4))\n",
    "print()\n",
    "\n",
    "print('Algorithm: \"movie average rating\"')\n",
    "print('RMSE:', np.round(np.mean(experiment_2[2]), 4))\n",
    "print('MAE:', np.round(np.mean(experiment_2[3]), 4))\n",
    "print()\n",
    "\n",
    "print('Algorithm: \"user average rating\"')\n",
    "print('RMSE:', np.round(np.mean(experiment_3[2]), 4))\n",
    "print('MAE:', np.round(np.mean(experiment_3[3]), 4))\n",
    "print()\n",
    "\n",
    "print('Algorithm: \"simple linear combination rating\"')\n",
    "print('RMSE:', np.round(np.mean(experiment_4[2]), 4))\n",
    "print('MAE:', np.round(np.mean(experiment_4[3]), 4))\n",
    "print()\n",
    "\n",
    "print('Algorithm: \"full linear combination rating\"')\n",
    "print('RMSE:', np.round(np.mean(experiment_5[2]), 4))\n",
    "print('MAE:', np.round(np.mean(experiment_5[3]), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] https://datanerd.blog/data-analysis-with-python-movielens/\n",
    "\n",
    "[2] https://github.com/codebasics/py/blob/master/ML/12_KFold_Cross_Validation/12_k_fold.ipynb\n",
    "\n",
    "[3] https://www.youtube.com/watch?v=R15LjD8aCzc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
